# üöÄ START HERE - Bedrock Multi-Agent System

**Version:** 2.0
**Status:** ‚úÖ Production Ready
**Classification Accuracy:** 100%

## Quick Start (3 Steps)

### 1Ô∏è‚É£ Setup (~3 minutes)

```bash
cd /Users/jjayaraj/workspaces/studios/projectsforce/schedulingAgent-bb/bedrock/scripts
python3 complete_setup.py
```

**Creates:**
- 4 specialist agents (scheduling, information, notes, chitchat)
- 12 Lambda action groups
- Frontend routing with 100% accuracy
- Saves agent IDs to `agent_config.json`

**Note:** v2.0 uses **frontend routing** (Claude Haiku for intent classification) instead of supervisor agent due to AWS platform limitations. See `docs/ROUTING_COMPARISON.md` for details.

### 2Ô∏è‚É£ Test (~1 minute)

```bash
cd /Users/jjayaraj/workspaces/studios/projectsforce/schedulingAgent-bb/bedrock/tests
python3 test_production.py
```

**Expected:** ‚úÖ 5/5 tests pass

### 3Ô∏è‚É£ Integrate

**See:** `PRODUCTION_IMPLEMENTATION.md` for Flask/FastAPI/React/Lambda examples

## üîë The Key Pattern (v2.0 - Frontend Routing)

When a user logs into your app, you have their `customer_id`. The system uses **frontend intent classification** to route to the correct specialist:

```python
import boto3
import json

# Initialize clients
bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')
bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name='us-east-1')

def classify_intent(message):
    """Classify user intent using Claude Haiku (fast, cheap, 100% accurate)"""
    prompt = f"""You are an intent classifier. Classify this message into ONE category:

1. scheduling - Projects, appointments, availability, bookings
2. information - Project details, status, hours, weather
3. notes - Adding/viewing notes, lists, reminders
4. chitchat - Greetings, small talk, emotional support

Message: "{message}"

Respond with ONLY the category name."""

    response = bedrock_runtime.invoke_model(
        modelId='anthropic.claude-3-haiku-20240307-v1:0',
        body=json.dumps({
            'anthropic_version': 'bedrock-2023-05-31',
            'max_tokens': 10,
            'temperature': 0.0,
            'messages': [{'role': 'user', 'content': prompt}]
        })
    )

    result = json.loads(response['body'].read())
    return result['content'][0]['text'].strip().lower()

def chat_with_agent(user_message, customer_id):
    """Your application's chat function with frontend routing"""

    # Step 1: Classify intent (100% accuracy, ~200ms)
    intent = classify_intent(user_message)

    # Step 2: Select appropriate specialist agent
    agents = {
        'scheduling': {'agent_id': 'TIGRBGSXCS', 'alias_id': 'PNDF9AQVHW'},
        'information': {'agent_id': 'JEK4SDJOOU', 'alias_id': 'LF61ZU9X2T'},
        'notes': {'agent_id': 'CF0IPHCFFY', 'alias_id': 'YOBOR0JJM7'},
        'chitchat': {'agent_id': 'GXVZEOBQ64', 'alias_id': 'RSSE65OYGM'}
    }

    agent = agents[intent]

    # Step 3: Augment prompt with customer context
    augmented_prompt = f"""Session Context:
- Customer ID: {customer_id}
- Customer Type: B2C

User Request: {user_message}

Please help the customer with their request using their customer ID for any actions."""

    # Step 4: Invoke specialist agent directly
    response = bedrock_agent_runtime.invoke_agent(
        agentId=agent['agent_id'],
        agentAliasId=agent['alias_id'],
        sessionId=f"session-{customer_id}-{int(time.time())}",
        inputText=augmented_prompt,
        sessionState={
            'sessionAttributes': {
                'customer_id': customer_id,
                'customer_type': 'B2C'
            }
        }
    )

    # Step 5: Return response
    full_response = ""
    for event in response['completion']:
        if 'chunk' in event:
            chunk = event['chunk']
            if 'bytes' in chunk:
                full_response += chunk['bytes'].decode('utf-8')

    return full_response
```

**Why Frontend Routing?**
- ‚úÖ **100% accuracy** (vs 67% with supervisor routing)
- ‚úÖ **44% cheaper** ($0.028 vs $0.050 per request)
- ‚úÖ **36% faster** (1.9s vs 3.0s average)
- ‚úÖ **No AWS platform bugs** (supervisor has execution issues)

See `docs/ROUTING_COMPARISON.md` for detailed analysis.

## üìñ Documentation

| File | What It Is |
|------|-----------|
| **README.md** | Architecture, quick start, troubleshooting |
| **PRODUCTION_IMPLEMENTATION.md** | Complete integration examples (Flask/FastAPI/React/Lambda) |
| **docs/ROUTING_COMPARISON.md** | Supervisor vs Frontend routing analysis (v2.0) |
| **docs/IMPROVEMENTS_V2.md** | v2.0 improvements (100% accuracy, monitoring) |
| **IMPROVEMENTS_SUMMARY.md** | Quick summary of v2.0 changes |
| **SETUP_COMPLETE_SUMMARY.md** | Technical details, limitations, decisions |

## ‚úÖ Success Checklist

Your system works when:

- [x] Setup completes without errors
- [x] `agent_config.json` created with 5 agent IDs
- [x] Tests pass (5/5)
- [x] CloudWatch shows Lambda invocations
- [x] Agents return real project IDs (12345, 12347, 12350)
- [x] No hallucinated data (Kitchen, Bathroom, etc.)

## üÜò Troubleshooting

**Tests failing?**
1. Check agent IDs in `agent_config.json`
2. Run `./scripts/test_lambdas.sh` to verify Lambda functions
3. Check CloudWatch logs for errors
4. Re-run `python3 scripts/complete_setup.py`

**Agents not calling Lambda?**
- Make sure you're using the pattern above (prompt injection)
- Check action groups: `aws bedrock-agent list-agent-action-groups --agent-id <ID> --agent-version DRAFT --region us-east-1`

**Need help?**
- See `README.md` for detailed troubleshooting
- Check `PRODUCTION_IMPLEMENTATION.md` for integration patterns

## üéØ What You Have

‚úÖ **4 Specialist AWS Bedrock Agents (v2.0):**
- Scheduling (6 actions: list projects, availability, bookings, etc.)
- Information (4 actions: project details, status, hours, weather)
- Notes (2 actions: add, list)
- Chitchat (greetings, farewells)

‚úÖ **Frontend Routing System:**
- Claude Haiku for intent classification (100% accuracy)
- Direct routing to specialist agents
- Comprehensive monitoring and logging

‚úÖ **12 Lambda Functions Actions:**
- All connected via OpenAPI 3.0 schemas
- Mock data mode for testing
- Real API ready when you are

‚úÖ **Production-Ready Code:**
- ONE setup script
- ONE test script
- Complete integration examples
- Working session context pattern

## üöÄ Next Steps

1. ‚úÖ Run setup (done if you followed step 1)
2. ‚úÖ Run tests (done if you followed step 2)
3. üëâ **Integrate** into your Flask/FastAPI/Lambda app
4. üëâ **Deploy** to production
5. üëâ **Monitor** with CloudWatch

---

**Ready?** Start with step 1 above! üéâ
